{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json \n",
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import trimesh\n",
    "from trimesh.transformations import transform_points\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pyrender\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on room images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-9-21 Python-3.9.12 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Importation of the Yolo model\n",
    "model = torch.hub.load(os.path.abspath('yolov5/'), 'custom', path=os.path.abspath('yolov5/yolov5s.pt'), source='local')  # local repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing test image\n",
    "img = cv2.imread(os.path.abspath('open3d_data/room_right.png'))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY )\n",
    "img = cv2.circle(img, (700, 400), 20, (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005.970154</td>\n",
       "      <td>299.992401</td>\n",
       "      <td>1347.299194</td>\n",
       "      <td>746.199585</td>\n",
       "      <td>0.534302</td>\n",
       "      <td>28</td>\n",
       "      <td>suitcase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008.942322</td>\n",
       "      <td>303.181671</td>\n",
       "      <td>1344.675903</td>\n",
       "      <td>742.474426</td>\n",
       "      <td>0.271587</td>\n",
       "      <td>56</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          xmin        ymin         xmax        ymax  confidence  class  \\\n",
       "0  1005.970154  299.992401  1347.299194  746.199585    0.534302     28   \n",
       "1  1008.942322  303.181671  1344.675903  742.474426    0.271587     56   \n",
       "\n",
       "       name  \n",
       "0  suitcase  \n",
       "1     chair  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the results (boxes)\n",
    "\n",
    "# Inference\n",
    "results = model(img, size=1080)  # includes NMS\n",
    "\n",
    "# Results\n",
    "results.show()  \n",
    "#results.show()  # or .show()\n",
    "\n",
    "#results = results.xyxy[0]  # img1 predictions (tensor)\n",
    "boxes = results.pandas().xyxy[0]  # img1 predictions (pandas)\n",
    "boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation of the point on pixel image : sphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Draw a line and the research of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if rotation is good\n",
    "\n",
    "sphere_coordinate1 = [0,0,0]\n",
    "mesh_sphere1 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere1.translate(sphere_coordinate1)\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_room, mesh_sphere1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_coordinate = sphere_coordinate1\n",
    "\n",
    "with open(os.path.abspath('open3d_data/room_test.json')) as json_file:\n",
    "    data_camera = json.load(json_file)\n",
    "extrinsic_matrix = np.array([[element for element in data_camera[\"extrinsic\"][i:i+4]] for i in range(0,16,4)])\n",
    "extrinsic_matrix = np.transpose(extrinsic_matrix)[0:3, :]\n",
    "intrinsic_matrix = np.array([[element for element in data_camera[\"intrinsic\"][\"intrinsic_matrix\"][i:i+3]] for i in range(0,9,3)])\n",
    "intrinsic_matrix = np.transpose(intrinsic_matrix)\n",
    "full_transfo_matrix = np.matmul(intrinsic_matrix, extrinsic_matrix)\n",
    "array_3d_augmented = np.array(sphere_coordinate + [1])\n",
    "array_2d_pixel = np.matmul(full_transfo_matrix, array_3d_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1, point2 = tuple(int(x) for x in array_2d_pixel[0:2]//20), tuple(int(x) for x in array_2d_pixel[0:2]//5)\n",
    "(x,y) = tuple(int(x) for x in array_2d_pixel[0:2]//array_2d_pixel[2])\n",
    "image = cv2.imread(os.path.abspath('open3d_data/room_test.png'))\n",
    "cv2.line(image, point1, point2, (255,0,0), 2)\n",
    "cv2.circle(image, (x,y), radius=10, color=(0, 0, 255))\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if triangulation is good\n",
    "pcd_room = o3d.io.read_point_cloud(\"C:/Users/raphaelanwarel.TRN/Documents/project/LIDAR/intro_O3D/data_test/fragment.ply\")\n",
    "center_chair_coor = space_coor\n",
    "mesh_sphere_chair = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere_chair.translate(center_chair_coor)\n",
    "o3d.visualization.draw_geometries([pcd_room, mesh_sphere_chair])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research of the 4 ground points with triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get Yolo Info \n",
    "\n",
    "def extract_biggest_confidence(boxes) :\n",
    "    confidence_column = boxes[\"confidence\"]\n",
    "    number_of_index = len(boxes.index)\n",
    "    if number_of_index > 1 :\n",
    "        max_index = confidence_column.idxmax()\n",
    "        return boxes.iloc[[max_index]]\n",
    "    return boxes\n",
    "\n",
    "def get_geometry_info(path, size=1080) :\n",
    "    img = cv2.imread(path + \".png\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY )\n",
    "\n",
    "    results = model(img, size=size)\n",
    "    boxes = results.pandas().xyxy[0]  # img1 predictions (pandas\n",
    "    chair_row = extract_biggest_confidence(boxes)\n",
    "    center_box_pixel = [(chair_row[\"xmin\"].to_numpy()[0] + chair_row[\"xmax\"].to_numpy()[0])/2, (chair_row[\"ymin\"].to_numpy()[0] + chair_row[\"ymax\"].to_numpy()[0])/2]\n",
    "\n",
    "    with open(path + \".json\") as json_file:\n",
    "        data_camera = json.load(json_file)\n",
    "\n",
    "    extrinsic_matrix = np.array([[element for element in data_camera[\"extrinsic\"][i:i+4]] for i in range(0,16,4)])\n",
    "    extrinsic_matrix = np.transpose(extrinsic_matrix)[0:3, :]\n",
    "    intrinsic_matrix = np.array([[element for element in data_camera[\"intrinsic\"][\"intrinsic_matrix\"][i:i+3]] for i in range(0,9,3)])\n",
    "    intrinsic_matrix = np.transpose(intrinsic_matrix)\n",
    "    full_transfo_matrix = np.matmul(intrinsic_matrix, extrinsic_matrix)\n",
    "\n",
    "    results = {\"coordinate_center\" : center_box_pixel, \"extrinsic_matrix\" : extrinsic_matrix, \"intrinsic_matrix\" : intrinsic_matrix, \"camera_matrix\" : full_transfo_matrix, \n",
    "                \"xmin\" : chair_row[\"xmin\"].to_numpy()[0], \"xmax\" : chair_row[\"xmax\"].to_numpy()[0], \"ymin\" : chair_row[\"ymin\"].to_numpy()[0], \"ymax\" : chair_row[\"ymax\"].to_numpy()[0]}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the triangulation system\n",
    "\n",
    "def create_system_matrix(results_1, results_2, focus=\"center\") :\n",
    "    g = {\"results_1\" : results_1, \"results_2\" : results_2}\n",
    "    for j in range(1,3) :\n",
    "\n",
    "        index_focus = 0\n",
    "\n",
    "        if focus == \"center\" : #Take the center of the box\n",
    "            g[\"x_\" + str(j)] = g[\"results_\" + str(j)][\"coordinate_center\"][0]\n",
    "            g[\"y_\" + str(j)] = g[\"results_\" + str(j)][\"coordinate_center\"][1]\n",
    "\n",
    "        if focus == \"left_right\" : # Put first the left picture (take the right bottom point)\n",
    "            index_focus = j%2       # and then the right (bottom left point)\n",
    "        elif focus == \"right_left\" :\n",
    "            index_focus = (j + 1)%2\n",
    "\n",
    "        if index_focus == 1 and focus != \"center\":\n",
    "            g[\"x_\" + str(j)] = g[\"results_\" + str(j)][\"xmax\"]\n",
    "            g[\"y_\" + str(j)] = g[\"results_\" + str(j)][\"ymax\"] \n",
    "        elif index_focus == 0 and focus != \"center\":  \n",
    "            g[\"x_\" + str(j)] = g[\"results_\" + str(j)][\"xmin\"]\n",
    "            g[\"y_\" + str(j)] = g[\"results_\" + str(j)][\"ymax\"]  \n",
    "\n",
    "    \n",
    "        for i in range(1,4) :\n",
    "            g[\"p\" + str(i) + \"_\" + str(j)] = g[\"results_\" + str(j)][\"camera_matrix\"][i-1, :]\n",
    "\n",
    "        \n",
    "        g[\"row1_\" + str(j)] = - np.multiply(g[\"x_\" + str(j)], g[\"p3_\" + str(j)]) + g[\"p1_\" + str(j)]\n",
    "        g[\"row2_\" + str(j)] = np.multiply(g[\"y_\" + str(j)], g[\"p3_\" + str(j)]) - g[\"p2_\" + str(j)]\n",
    "\n",
    "        \n",
    "\n",
    "    return np.matrix([g[\"row1_1\"], g[\"row2_1\"], g[\"row1_2\"], g[\"row2_2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-9-21 Python-3.9.12 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Apply these function to triangulate one point\n",
    "\n",
    "path_img_left = os.path.abspath('open3d_data/room_left')\n",
    "path_img_right = os.path.abspath('open3d_data/room_right')\n",
    "model = torch.hub.load(os.path.abspath('yolov5/'), 'custom', path=os.path.abspath('yolov5/yolov5s.pt'), source='local')  \n",
    "\n",
    "results_left = get_geometry_info(path_img_left)\n",
    "results_right = get_geometry_info(path_img_right)\n",
    "\n",
    "system_matrix = create_system_matrix(results_left, results_right, focus=\"left_right\")\n",
    "(u, s, vh) = np.linalg.svd(system_matrix)\n",
    "space_coor = vh[-1, :]\n",
    "space_coor = np.array([space_coor[0,i] for i in range(4)])\n",
    "space_coor = (space_coor/space_coor[-1])[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "source": [
    "# Check if triangulation is good\n",
    "pcd_room = o3d.io.read_point_cloud(\"C:/Users/raphaelanwarel.TRN/Documents/project/LIDAR/intro_O3D/data_test/fragment.ply\")\n",
    "center_chair_coor = space_coor\n",
    "mesh_sphere_chair = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere_chair.translate(center_chair_coor)\n",
    "o3d.visualization.draw_geometries([pcd_room, mesh_sphere_chair])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing a chair by something else : Rotating and croping the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the room\n",
    "vol = o3d.visualization.read_selection_polygon_volume(\"C:/Users/raphaelanwarel.TRN/Documents/project/LIDAR/intro_O3D/data_test/cropped.json\")\n",
    "pcd_room = o3d.io.read_point_cloud(\"C:/Users/raphaelanwarel.TRN/Documents/project/LIDAR/intro_O3D/data_test/fragment.ply\")\n",
    "\n",
    "#o3d.visualization.draw_geometries([pcd_room], width=1400, height=900)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Rotating and translating the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation and translation function\n",
    "index_ground = 191570\n",
    "\n",
    "def rotation_toward_axis(mesh, initial_orientation, final_orientation=np.array([0, 0, 1])) :\n",
    "\n",
    "    ### Make the mesh going in the direction (0, 0, 1)\n",
    "    norm = np.linalg.norm(initial_orientation)\n",
    "    initial_orientation = initial_orientation / norm\n",
    "    norm = np.linalg.norm(final_orientation)\n",
    "    final_orientation = final_orientation / norm\n",
    "       \n",
    "    # Computation of Rotation matrix\n",
    "    v = np.cross(initial_orientation, final_orientation)\n",
    "    s, c = np.linalg.norm(v), np.dot(initial_orientation, final_orientation)\n",
    "\n",
    "    if c != -1 :\n",
    "        v_bracket = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])\n",
    "        R = np.eye(3) + v_bracket + np.matmul(v_bracket, v_bracket) * (1 - c)/s**2\n",
    "\n",
    "    else :\n",
    "        R = -np.eye(3)\n",
    "        R[1,1] = 1\n",
    "    \n",
    "    # Transformation Matrix\n",
    "    T = np.eye(4)\n",
    "    T[0:3, 0:3] = R\n",
    "    if np.linalg.norm(initial_orientation) != 0:\n",
    "        mesh = mesh.transform(T)\n",
    "\n",
    "\n",
    "def ground_to_zero(mesh, z_ground_coordinate) :\n",
    "    # Put the groud at z=0 after rotation\n",
    "    T = np.eye(4)\n",
    "    T[2, 3] = - z_ground_coordinate\n",
    "    mesh = mesh.transform(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation and translation of the room\n",
    "pcd_room.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=.1, max_nn=100))\n",
    "initial_orientation = pcd_room.normals[index_ground]\n",
    "rotation_toward_axis(pcd_room, initial_orientation)\n",
    "\n",
    "z_ground_coordinate = np.asarray(pcd_room.points)[index_ground][2]\n",
    "ground_to_zero(pcd_room, z_ground_coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "# Check if rotation is good\n",
    "sphere_coordinate1 = [0,0,0]\n",
    "mesh_sphere1 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere1.translate(sphere_coordinate1)\n",
    "\n",
    "sphere_coordinate2 = [0,0,1]\n",
    "mesh_sphere2 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere2.translate(sphere_coordinate2)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_room,mesh_sphere1, mesh_sphere2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Finding 4 good points and croping : naive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) Afther picking points, press q for close the window\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n[Open3D INFO] Picked point #194040 (2.0, 1.7, -2.4) to add in queue.\\n[Open3D INFO] Picked point #156031 (2.2, 0.8, -2.4) to add in queue.\\n[Open3D INFO] Picked point #162899 (2.8, 0.81, -2.4) to add in queue.\\n[Open3D INFO] No point has been picked.\\n[Open3D INFO] Picked point #193799 (2.7, 1.7, -2.4) to add in queue.\\n'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interactive function to select points\n",
    "def pick_points(pcd):\n",
    "    print(\"\")\n",
    "    print(\n",
    "        \"1) Please pick at least three correspondences using [shift + left click]\"\n",
    "    )\n",
    "    print(\"   Press [shift + right click] to undo point picking\")\n",
    "    print(\"2) Afther picking points, press q for close the window\")\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()  # user picks points\n",
    "    vis.destroy_window()\n",
    "    print(\"\")\n",
    "    return vis.get_picked_points()\n",
    "\n",
    "pick_points(pcd_room)\n",
    "\n",
    "''' \n",
    "[Open3D INFO] Picked point #194040 (2.0, 1.7, -2.4) to add in queue.\n",
    "[Open3D INFO] Picked point #156031 (2.2, 0.8, -2.4) to add in queue.\n",
    "[Open3D INFO] Picked point #162899 (2.8, 0.81, -2.4) to add in queue.\n",
    "[Open3D INFO] No point has been picked.\n",
    "[Open3D INFO] Picked point #193799 (2.7, 1.7, -2.4) to add in queue.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of 4 interesting points\n",
    "index1 = 194040\n",
    "index2 = 156031\n",
    "index3 = 162899\n",
    "index4 = 193799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping of the room and the old chair\n",
    "delta_z = 2\n",
    "epsilon_z = delta_z /80\n",
    "\n",
    "\n",
    "corners = np.array([ \n",
    "    np.asarray(pcd_room.points)[index1] + np.array([0, 0, epsilon_z]),\n",
    "    np.asarray(pcd_room.points)[index2] + np.array([0, 0, epsilon_z]),\n",
    "    np.asarray(pcd_room.points)[index3] + np.array([0, 0, epsilon_z]),\n",
    "    np.asarray(pcd_room.points)[index4] + np.array([0, 0, epsilon_z]),\n",
    "    np.asarray(pcd_room.points)[index1] + np.array([0, 0, delta_z]),\n",
    "    np.asarray(pcd_room.points)[index2] + np.array([0, 0, delta_z]),\n",
    "    np.asarray(pcd_room.points)[index3] + np.array([0, 0, delta_z]),\n",
    "    np.asarray(pcd_room.points)[index4] + np.array([0, 0, delta_z]),\n",
    "])\n",
    "\n",
    "\n",
    "cuboid_points = corners\n",
    "points = o3d.utility.Vector3dVector(cuboid_points)\n",
    "oriented_bounding_box = o3d.geometry.OrientedBoundingBox.create_from_points(points)\n",
    "old_chair = pcd_room.crop(oriented_bounding_box)\n",
    "\n",
    "dists = pcd_room.compute_point_cloud_distance(old_chair)\n",
    "dists = np.asarray(dists)\n",
    "ind = np.where(dists > .01)[0]\n",
    "pcd_without_chair = pcd_room.select_by_index(ind)\n",
    "\n",
    "#o3d.visualization.draw_geometries([pcd_without_chair, oriented_bounding_box])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Finding 4 good points and croping : triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-9-21 Python-3.9.12 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results_1': {'coordinate_center': [1169.3529968261719, 577.9370574951172], 'extrinsic_matrix': array([[    0.90972,    -0.41502,   -0.012811,     -1.1662],\n",
      "       [  -0.066453,    -0.11507,    -0.99113,      0.7878],\n",
      "       [    0.40986,     0.90251,    -0.13226,     0.16613]]), 'intrinsic_matrix': array([[     935.31,           0,       959.5],\n",
      "       [          0,      935.31,       539.5],\n",
      "       [          0,           0,           1]]), 'camera_matrix': array([[     1244.1,      477.78,     -138.89,     -931.36],\n",
      "       [     158.97,      379.28,     -998.37,      826.46],\n",
      "       [    0.40986,     0.90251,    -0.13226,     0.16613]]), 'xmin': 985.8502807617188, 'xmax': 1352.855712890625, 'ymin': 387.5121154785156, 'ymax': 768.3619995117188}, 'results_2': {'coordinate_center': [1176.6007385253906, 523.0942840576172], 'extrinsic_matrix': array([[    0.94314,     0.28759,    -0.16665,     -2.1393],\n",
      "       [  -0.064604,    -0.33321,    -0.94064,     0.97319],\n",
      "       [   -0.32604,     0.89792,    -0.29568,      1.8129]]), 'intrinsic_matrix': array([[     935.31,           0,       959.5],\n",
      "       [          0,      935.31,       539.5],\n",
      "       [          0,           0,           1]]), 'camera_matrix': array([[     569.29,      1130.5,     -439.58,     -261.47],\n",
      "       [    -236.33,      172.78,     -1039.3,      1888.3],\n",
      "       [   -0.32604,     0.89792,    -0.29568,      1.8129]]), 'xmin': 1005.9002075195312, 'xmax': 1347.30126953125, 'ymin': 299.9737243652344, 'ymax': 746.21484375}}\n",
      "{'results_1': {'coordinate_center': [1169.3529968261719, 577.9370574951172], 'extrinsic_matrix': array([[    0.90972,    -0.41502,   -0.012811,     -1.1662],\n",
      "       [  -0.066453,    -0.11507,    -0.99113,      0.7878],\n",
      "       [    0.40986,     0.90251,    -0.13226,     0.16613]]), 'intrinsic_matrix': array([[     935.31,           0,       959.5],\n",
      "       [          0,      935.31,       539.5],\n",
      "       [          0,           0,           1]]), 'camera_matrix': array([[     1244.1,      477.78,     -138.89,     -931.36],\n",
      "       [     158.97,      379.28,     -998.37,      826.46],\n",
      "       [    0.40986,     0.90251,    -0.13226,     0.16613]]), 'xmin': 985.8502807617188, 'xmax': 1352.855712890625, 'ymin': 387.5121154785156, 'ymax': 768.3619995117188}, 'results_2': {'coordinate_center': [1176.6007385253906, 523.0942840576172], 'extrinsic_matrix': array([[    0.94314,     0.28759,    -0.16665,     -2.1393],\n",
      "       [  -0.064604,    -0.33321,    -0.94064,     0.97319],\n",
      "       [   -0.32604,     0.89792,    -0.29568,      1.8129]]), 'intrinsic_matrix': array([[     935.31,           0,       959.5],\n",
      "       [          0,      935.31,       539.5],\n",
      "       [          0,           0,           1]]), 'camera_matrix': array([[     569.29,      1130.5,     -439.58,     -261.47],\n",
      "       [    -236.33,      172.78,     -1039.3,      1888.3],\n",
      "       [   -0.32604,     0.89792,    -0.29568,      1.8129]]), 'xmin': 1005.9002075195312, 'xmax': 1347.30126953125, 'ymin': 299.9737243652344, 'ymax': 746.21484375}}\n"
     ]
    }
   ],
   "source": [
    "# Find the center and one surrounding point (not in the pointcloud) + finding the symmetric and all the other points\n",
    "\n",
    "correction_coef = 0.8 # Percentage of distance reduction between center and surrounding points\n",
    "\n",
    "path_img_left = os.path.abspath('open3d_data/room_left')\n",
    "path_img_right = os.path.abspath('open3d_data/room_right')\n",
    "model = torch.hub.load(os.path.abspath('yolov5/'), 'custom', path=os.path.abspath('yolov5/yolov5s.pt'), source='local')  \n",
    "\n",
    "results_left = get_geometry_info(path_img_left)\n",
    "results_right = get_geometry_info(path_img_right)\n",
    "\n",
    "system_matrix = create_system_matrix(results_left, results_right, focus=\"center\")\n",
    "(u, s, vh) = np.linalg.svd(system_matrix)\n",
    "space_coor_center = vh[-1, :]\n",
    "space_coor_center = np.array([space_coor_center[0,i] for i in range(4)])\n",
    "space_coor_center = (space_coor_center/space_coor_center[-1])[:3]\n",
    "\n",
    "system_matrix = create_system_matrix(results_left, results_right, focus=\"left_right\")\n",
    "(u, s, vh) = np.linalg.svd(system_matrix)\n",
    "space_coor_out_1 = vh[-1, :]\n",
    "space_coor_out_1 = np.array([space_coor_out_1[0,i] for i in range(4)])\n",
    "space_coor_out_1 = (space_coor_out_1/space_coor_out_1[-1])[:3]\n",
    "space_coor_out_1[2] = 0\n",
    "\n",
    "## Correction of space_coor_out_1\n",
    "space_coor_out_1 = space_coor_center + correction_coef*(space_coor_out_1 - space_coor_center)\n",
    "\n",
    "\n",
    "# Symmetrical points\n",
    "space_coor_out_3 = space_coor_center + (space_coor_center - space_coor_out_1)\n",
    "space_coor_out_3[2] = 0\n",
    "\n",
    "angle = np.pi/2\n",
    "rotation_matrix = np.mat([[np.cos(angle), -np.sin(angle), 0], [np.sin(angle), np.cos(angle), 0], [0, 0, 0]])\n",
    "\n",
    "space_coor_out_2 = space_coor_center + np.matmul(rotation_matrix, space_coor_out_1 - space_coor_center)\n",
    "space_coor_out_2 = np.array([space_coor_out_2[0,i] for i in range(3)])\n",
    "space_coor_out_2[2] = 0\n",
    "\n",
    "space_coor_out_4 = space_coor_center + np.matmul(rotation_matrix, space_coor_out_3 - space_coor_center)\n",
    "space_coor_out_4 = np.array([space_coor_out_4[0,i] for i in range(3)])\n",
    "space_coor_out_4[2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if triangulation is good (out of pointcloud)\n",
    "center_chair_coor = space_coor_center\n",
    "mesh_sphere_chair = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere_chair.translate(center_chair_coor)\n",
    "\n",
    "out_chair_coor_1 = space_coor_out_1\n",
    "mesh_out_1 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_out_1.translate(space_coor_out_1)\n",
    "\n",
    "out_chair_coor_3 = space_coor_out_3\n",
    "mesh_out_3 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_out_3.translate(space_coor_out_3)\n",
    "\n",
    "out_chair_coor_2 = space_coor_out_2\n",
    "mesh_out_2 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_out_2.translate(space_coor_out_2)\n",
    "\n",
    "out_chair_coor_4 = space_coor_out_4\n",
    "mesh_out_4 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_out_4.translate(space_coor_out_4)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_room, mesh_sphere_chair, mesh_out_1, mesh_out_3, mesh_out_2, mesh_out_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the nearest point (in the pointcloud) of these points\n",
    "\n",
    "def find_nearest(pcd, point):\n",
    "    pcd_points = np.asarray(pcd.points)\n",
    "    idx = (np.linalg.norm(pcd_points - point, axis=1)).argmin()\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to get the 4 index\n",
    "\n",
    "index1_tri = find_nearest(pcd_room, space_coor_out_1)\n",
    "index2_tri = find_nearest(pcd_room, space_coor_out_2)\n",
    "index3_tri = find_nearest(pcd_room, space_coor_out_3)\n",
    "index4_tri = find_nearest(pcd_room, space_coor_out_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "source": [
    "# Cropping of the room and the old chair\n",
    "delta_z = 2\n",
    "epsilon_z = delta_z /80\n",
    "\n",
    "\n",
    "corners = np.array([ \n",
    "    np.asarray(pcd_room.points)[index1_tri] + np.array([0, 0, epsilon_z]),\n",
    "    np.asarray(pcd_room.points)[index2_tri] + np.array([0, 0, epsilon_z]),\n",
    "    np.asarray(pcd_room.points)[index3_tri] + np.array([0, 0, epsilon_z]),\n",
    "    np.asarray(pcd_room.points)[index4_tri] + np.array([0, 0, epsilon_z]),\n",
    "    np.asarray(pcd_room.points)[index1_tri] + np.array([0, 0, delta_z]),\n",
    "    np.asarray(pcd_room.points)[index2_tri] + np.array([0, 0, delta_z]),\n",
    "    np.asarray(pcd_room.points)[index3_tri] + np.array([0, 0, delta_z]),\n",
    "    np.asarray(pcd_room.points)[index4_tri] + np.array([0, 0, delta_z]),\n",
    "])\n",
    "\n",
    "\n",
    "cuboid_points = corners\n",
    "points = o3d.utility.Vector3dVector(cuboid_points)\n",
    "oriented_bounding_box = o3d.geometry.OrientedBoundingBox.create_from_points(points)\n",
    "old_chair = pcd_room.crop(oriented_bounding_box)\n",
    "\n",
    "dists = pcd_room.compute_point_cloud_distance(old_chair)\n",
    "dists = np.asarray(dists)\n",
    "ind = np.where(dists > .01)[0]\n",
    "pcd_without_chair = pcd_room.select_by_index(ind)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_without_chair, oriented_bounding_box])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a clean old chair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the old chair\n",
    "def cleaning_cropped_object(mesh) :\n",
    "\n",
    "    # Detect the biggest object in the point cloud\n",
    "    # Create 2 differents points cloud : one with the big object, and one with the rest\n",
    "    mesh_initial = copy.deepcopy(mesh)\n",
    "    with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "        labels = np.array(\n",
    "            mesh.cluster_dbscan(eps=0.02, min_points=10, print_progress=True))\n",
    "\n",
    "    biggest_label = np.unique(labels, return_counts=True)[0][np.unique(labels, return_counts=True)[1].argmax()]\n",
    "    big_object_points, big_object_colors, artefacts_points, artefacts_colors = [], [], [], []\n",
    "    \n",
    "    for i in range(len(labels)) :\n",
    "        if labels[i] == biggest_label :\n",
    "            big_object_points.append(np.asarray(mesh_initial.points)[i])\n",
    "            big_object_colors.append(np.asarray(mesh_initial.colors)[i])\n",
    "        else :\n",
    "            artefacts_points.append(np.asarray(mesh_initial.points)[i])\n",
    "            artefacts_colors.append(np.asarray(mesh_initial.colors)[i])\n",
    "\n",
    "    big_object, artefacts = o3d.geometry.PointCloud(), o3d.geometry.PointCloud()\n",
    "    big_object.points, artefacts.points = o3d.utility.Vector3dVector(np.array(big_object_points)), o3d.utility.Vector3dVector(np.array(artefacts_points))\n",
    "    big_object.colors, artefacts.colors = o3d.utility.Vector3dVector(np.array(big_object_colors)), o3d.utility.Vector3dVector(np.array(artefacts_colors))\n",
    "    del mesh_initial\n",
    "\n",
    "    return big_object, artefacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D DEBUG] Precompute neighbors.\n",
      "[Open3D DEBUG] Done Precompute neighbors.\n",
      "[Open3D DEBUG] Compute Clusters\n",
      "[Open3D DEBUG] Done Compute Clusters: 4\n"
     ]
    }
   ],
   "source": [
    "# Cleaning : Old chair and artefacts\n",
    "cleaned_old_chair, artefacts = cleaning_cropped_object(old_chair)\n",
    "artefacts, ind = artefacts.remove_statistical_outlier(nb_neighbors=20,\n",
    "                                                    std_ratio=2.0)\n",
    "#o3d.visualization.draw_geometries([pcd_without_chair])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Merging artefact with the cropped room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the cleaned cropped room\n",
    "pcd_without_chair_cleaned = o3d.geometry.PointCloud()\n",
    "pcd_without_chair_cleaned.points = o3d.utility.Vector3dVector(np.concatenate((np.asarray(pcd_without_chair.points), np.asarray(artefacts.points)), axis=0))\n",
    "pcd_without_chair_cleaned.colors = o3d.utility.Vector3dVector(np.concatenate((np.asarray(pcd_without_chair.colors), np.asarray(artefacts.colors)), axis=0))\n",
    "#o3d.visualization.draw_geometries([pcd_without_chair_cleaned])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotate, Scale and move the new chair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importation of new chair and downsample if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 15611 points.\n"
     ]
    }
   ],
   "source": [
    "# Load new chair and downsample\n",
    "new_chair = o3d.io.read_point_cloud(os.path.abspath('open3d_data/chair/wooden_chair.ply'))\n",
    "\n",
    "while len(new_chair.points) > len(cleaned_old_chair.points) :\n",
    "    new_chair = new_chair.uniform_down_sample(2)\n",
    "    \n",
    "new_chair.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=.1, max_nn=100))\n",
    "o3d.visualization.draw_geometries([new_chair], width=1400, height=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new chair and downsample\n",
    "new_chair = o3d.io.read_point_cloud(os.path.abspath('open3d_data/chair/Patchwork_chair.ply'))\n",
    "\n",
    "while len(new_chair.points) > len(cleaned_old_chair.points) :\n",
    "    new_chair = new_chair.uniform_down_sample(2)\n",
    "\n",
    "new_chair.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=.1, max_nn=100))\n",
    "#o3d.visualization.draw_geometries([new_chair], width=1400, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Find the good rotation : Naive method (Point selection on new chair)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) Afther picking points, press q for close the window\n",
      "[Open3D INFO] Picked point #14500 (-6.9, -61., -17.) to add in queue.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  \\nPicked point #11002 (-0.054, 0.036, -0.83) to add in queue. For the patchwork chair\\n'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking a point\n",
    "\n",
    "def pick_points(pcd):\n",
    "    print(\"\")\n",
    "    print(\n",
    "        \"1) Please pick at least three correspondences using [shift + left click]\"\n",
    "    )\n",
    "    print(\"   Press [shift + right click] to undo point picking\")\n",
    "    print(\"2) Afther picking points, press q for close the window\")\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()  # user picks points\n",
    "    vis.destroy_window()\n",
    "    print(\"\")\n",
    "    return vis.get_picked_points()\n",
    "\n",
    "new_chair.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=.1, max_nn=20))\n",
    "pick_points(new_chair)\n",
    "\"\"\"  \n",
    "Picked point #11002 (-0.054, 0.036, -0.83) to add in queue. For the patchwork chair\n",
    "Picked point #14500 (-6.9, -61., -17.) to add in queue. For the wooden chair\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation of the chair toward z\n",
    "good_index_new_chair_patch = 11002\n",
    "good_index_new_chair = 14500\n",
    "initial_orientation = np.asarray(new_chair.normals[good_index_new_chair]) #Normals are buggy with the chair\n",
    "rotation_toward_axis(new_chair, initial_orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking direction of the chair\n",
    "\n",
    "sphere_coordinate1 = [0,0,0]\n",
    "mesh_sphere1 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere1.translate(sphere_coordinate1)\n",
    "\n",
    "sphere_coordinate2 = [0,0,1]\n",
    "mesh_sphere2 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere2.translate(sphere_coordinate2)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_without_chair_cleaned, new_chair, mesh_sphere1, mesh_sphere2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Find the good z translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions translation chair\n",
    "\n",
    "def translation_chair_z(chair_mesh):\n",
    "    # Find the lowest point of the rotated chair\n",
    "    # Translation to put this point at z=0\n",
    "    lowest_z = np.min(np.asarray(chair_mesh.points)[:, 2])\n",
    "    T = np.eye(4)\n",
    "    T[2, 3] = - lowest_z\n",
    "    chair_mesh = chair_mesh.transform(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply translation transformation\n",
    "translation_chair_z(new_chair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking direction of the chair\n",
    "\n",
    "sphere_coordinate1 = [0,0,0]\n",
    "mesh_sphere1 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere1.translate(sphere_coordinate1)\n",
    "\n",
    "sphere_coordinate2 = [0,0,1]\n",
    "mesh_sphere2 = o3d.geometry.TriangleMesh.create_sphere(radius = .1)\n",
    "mesh_sphere2.translate(sphere_coordinate2)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_without_chair_cleaned, new_chair, mesh_sphere1, mesh_sphere2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Same direction as the old chair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing mean value for bottom upper part, fetching on x and y coordinate \n",
    "\n",
    "height_old_chair = np.max(np.asarray(cleaned_old_chair.points)[:, 2])\n",
    "height_new_chair = np.max(np.asarray(new_chair.points)[:, 2]) # The ground is at z=0\n",
    "\n",
    "cleaned_old_chair.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=.1, max_nn=100))\n",
    "new_chair.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=.1*height_new_chair/height_old_chair, max_nn=100))\n",
    "\n",
    "n = len(np.asarray(new_chair.normals))\n",
    "direction_new_chair = np.mean(np.array([np.asarray(new_chair.normals)[i] for i in range(n) if np.asarray(new_chair.points)[i][2] >= height_new_chair/2]), axis=0)\n",
    "direction_new_chair[2] = 0\n",
    "\n",
    "n = len(np.asarray(cleaned_old_chair.normals))\n",
    "direction_old_chair = np.mean(np.array([np.asarray(cleaned_old_chair.normals)[i] for i in range(n) if np.asarray(cleaned_old_chair.points)[i][2] >= height_old_chair/2]), axis=0)\n",
    "direction_old_chair[2] = 0\n",
    "\n",
    "rotation_toward_axis(new_chair, initial_orientation=direction_new_chair, final_orientation=direction_old_chair)\n",
    "\n",
    "o3d.visualization.draw_geometries([new_chair, cleaned_old_chair])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Find the good scaling and translation : fit in the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old method\n",
    "def max_distance(points) :\n",
    "    hull = ConvexHull(points)\n",
    "    # Extract the points forming the hull\n",
    "    hullpoints = points[hull.vertices,:]\n",
    "    hdist = cdist(hullpoints, hullpoints, metric='euclidean')\n",
    "    return np.max(hdist)\n",
    "\n",
    "# Transform : same height for both chairs\n",
    "old_height = max_distance(np.asarray(old_chair.points))\n",
    "new_height = max_distance(np.asarray(new_chair.points))\n",
    "\n",
    "scale_coef = old_height / new_height\n",
    "\n",
    "# Transformation Matrix\n",
    "T = scale_coef*np.eye(4)\n",
    "T[3, 3] = 1\n",
    "new_chair = new_chair.transform(T)\n",
    "\n",
    "# Scale and translate in the bounding box\n",
    "index1 = 194040\n",
    "index2 = 156031\n",
    "index3 = 162899\n",
    "index4 = 193799\n",
    "good_index_new_chair = 11002  #Index of a point in the middle of the new chair\n",
    "list_index = [index1, index2, index3, index4]\n",
    "scaling_in_bounding_box(chair_mesh=new_chair, room_mesh=pcd_room, list_index=list_index)\n",
    "translating_in_bounding_box(chair_mesh=new_chair, room_mesh=pcd_room, list_index=list_index, index_middle_chair=good_index_new_chair) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions of scaling and translation\n",
    "\n",
    "def scaling_in_bounding_box(chair_mesh, room_mesh, list_index) :\n",
    "\n",
    "    # Fit the chair in the box\n",
    "    chair_points = np.asarray(chair_mesh.points)\n",
    "    room_points = np.asarray(room_mesh.points)\n",
    "\n",
    "    hull = ConvexHull(chair_points)\n",
    "    # Extract the points forming the hull (only x and y coordinate)\n",
    "    hullpoints = chair_points[hull.vertices,0:2]\n",
    "    hdist = cdist(hullpoints, hullpoints, metric='euclidean')\n",
    "    diameter_chair = np.max(hdist)\n",
    "\n",
    "    # Find the smallest distance between two vertices\n",
    "    hullpoints_box = room_points[list_index,0:2]\n",
    "    hdist = cdist(hullpoints_box, hullpoints_box, metric='euclidean')\n",
    "    diameter_box = np.min(hdist[np.nonzero(hdist)])\n",
    "\n",
    "\n",
    "    scale_coef = diameter_box / diameter_chair\n",
    "\n",
    "    # Transformation Matrix\n",
    "    T = scale_coef*np.eye(4)\n",
    "    T[3, 3] = 1\n",
    "    chair_mesh = chair_mesh.transform(T)\n",
    "\n",
    "def translating_in_bounding_box(chair_mesh, room_mesh, list_index, index_middle_chair) :\n",
    "    \n",
    "    # Move the middle point of the chair to the box barycenter\n",
    "    vertices_xy = np.asarray(room_mesh.points)[list_index,0:2]\n",
    "    box_barycenter = np.sum(vertices_xy, axis=0)/4\n",
    "    chair_barycenter = np.asarray(chair_mesh.points)[index_middle_chair,0:2]\n",
    "    translation = box_barycenter - chair_barycenter\n",
    "\n",
    "    T = np.eye(4)\n",
    "    T[0:2, 3] = translation\n",
    "    chair_mesh = chair_mesh.transform(T)\n",
    "\n",
    "def translating_center_chair(new_chair_mesh, old_chair_mesh, list_index, index_middle_chair) :\n",
    "    \n",
    "    # Move the middle point of the chair to the box barycenter\n",
    "    vertices_xy = np.asarray(old_chair_mesh.points)[list_index,0:2]\n",
    "    old_chair_barycenter = np.sum(vertices_xy, axis=0)/4\n",
    "    new_chair_barycenter = np.asarray(new_chair_mesh.points)[index_middle_chair,0:2]\n",
    "    translation = old_chair_barycenter - new_chair_barycenter\n",
    "\n",
    "    T = np.eye(4)\n",
    "    T[0:2, 3] = translation\n",
    "    new_chair_mesh = new_chair_mesh.transform(T)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find a bounding box for cleaned old_chair\n",
    "\n",
    "def surrounding_box(pcd) :\n",
    "\n",
    "    points = np.asarray(pcd.points)\n",
    "    index1 = np.argmax(points[:, 0])\n",
    "    index2 = np.argmax(points[:, 1])\n",
    "    index3 = np.argmin(points[:, 0])\n",
    "    index4 = np.argmin(points[:, 1])\n",
    "    return [index1, index2, index3, index4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and translate in the bounding box\n",
    "\n",
    "good_index_new_chair = 11002  #Index of a point in the middle of the new chair\n",
    "list_index = surrounding_box(cleaned_old_chair)\n",
    "scaling_in_bounding_box(chair_mesh=new_chair, room_mesh=pcd_room, list_index=list_index)\n",
    "translating_center_chair(new_chair_mesh=new_chair, old_chair_mesh=cleaned_old_chair, list_index=list_index, index_middle_chair=good_index_new_chair)\n",
    "o3d.visualization.draw_geometries([pcd_without_chair_cleaned, new_chair, mesh_sphere1, mesh_sphere2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ba4d70c032d5433f9725ada45b690c971c0fb7ca184e950a033abb7cf72a6eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
